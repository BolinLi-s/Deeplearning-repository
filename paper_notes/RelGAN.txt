RelGAN是ICCV2019的一篇关于面部不同属性单独调整的网络

过去的很多网络只能做两个域之间的转换，如果增加转换功能只能重新训练新的网络，而且在转换的同时不能很好地控制其他属性的变化。针对这个问题作者提出了针对相对分布的网络，可以单独控制某一个属性的变化和变化的程度。

贡献：1.只基于分布的改变，不需要输入图片的全部分布
2.决定是否输入输出对匹配相对分布
3.提升插值质量
4.这个方法比现有的SOTA好

multi-domain的方法有starGAN和AttGAN，与这两个不同，relGAN是基于相对分布的结构，其次starGAN和attGAN都使用了辅助分类器，但RelGAN使用的是matching-aware判别器，最后，relGAN使用了连续性操作的插值判别器。

这篇文章的方法是：
通过cGAN将输入x和相对分布向量v映射到y，分布向量的数值分别是-1,0,1，分别代表去除保持和添加
α是代表插值率

损失函数分别是这几项：
对抗loss没啥说的
条件对抗loss中匹配判别器来判断原图和目标图之间是否匹配分布向量
算法描述如下：分别计算三个域之间的分布向量，除了真假判断外，还引入wrong triplet，让判别器习得相对分布的差别
重建loss由cycleloss和自重建loss组成
插值loss使得判别器来学习插值程度（这个程度是距离两个分布之间的最近的一个距离）

全loss中加入正交规范化，并且每个loss都加入了一些权重